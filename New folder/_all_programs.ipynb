{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#LAB -- 5\n",
        "#Eigenvalue\n",
        "import numpy as np\n",
        "from numpy.linalg import qr\n",
        "a = np.array([[0, 2,3], \n",
        "              [2, 3,5],\n",
        "              [3 ,4,5]])\n",
        "\n",
        "p = [1, 5, 10, 20,30]\n",
        "for i in range(30):\n",
        "    q, r = qr(a)\n",
        "    a = np.dot(r, q)\n",
        "    if i+1 in p:\n",
        "        print(f'Iteration {i+1}:')\n",
        "        print(a)\n",
        "#Eigenvector corresponding to maximum eigenvalue\n",
        "import numpy as np\n",
        "def normalize(x):\n",
        "    fac = abs(x).max()\n",
        "    x_n = x / x.max()\n",
        "    return fac, x_n\n",
        "x = np.array([1, 1,1])\n",
        "a = np.array([[0, 2,3], \n",
        "              [2, 3,5],\n",
        "              [3 ,4,5]])\n",
        "\n",
        "for i in range(8):\n",
        "    x = np.dot(a, x)\n",
        "    lambda_1, x = normalize(x)\n",
        "    \n",
        "print('Eigenvalue:', lambda_1)\n",
        "print('Eigenvector:', x)\n",
        "\n",
        "#Eigenvector corresponding to minimum eigenvalue\n",
        "from numpy.linalg import inv\n",
        "a_inv = inv(a)\n",
        "\n",
        "for i in range(8):\n",
        "    x = np.dot(a_inv, x)\n",
        "    lambda_1, x = normalize(x)\n",
        "    \n",
        "print('Eigenvalue:', lambda_1)\n",
        "print('Eigenvector:', x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55yzckYv-39f",
        "outputId": "7d1d5a64-e5f1-4009-c9bf-bbb374ba21cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1:\n",
            "[[ 8.53846154 -3.61363945 -0.19048483]\n",
            " [-3.75100002 -0.01015965  0.07326229]\n",
            " [ 0.80003628  0.07326229 -0.52830189]]\n",
            "Iteration 5:\n",
            "[[ 9.89139701e+00  4.83448514e-01 -8.05614047e-01]\n",
            " [-1.70807615e-03 -1.37991119e+00 -3.34245572e-01]\n",
            " [ 5.73684428e-06  5.75420311e-03 -5.11485813e-01]]\n",
            "Iteration 10:\n",
            "[[ 9.89132336e+00  4.90459322e-01  8.02350924e-01]\n",
            " [ 8.96249054e-08 -1.37763286e+00  3.40080374e-01]\n",
            " [ 2.16201094e-12 -4.12734342e-05 -5.13690497e-01]]\n",
            "Iteration 20:\n",
            "[[ 9.89132336e+00  4.90497562e-01  8.02327496e-01]\n",
            " [ 2.46134495e-16 -1.37761662e+00  3.40121639e-01]\n",
            " [ 3.08644398e-25 -2.14547383e-09 -5.13706744e-01]]\n",
            "Iteration 30:\n",
            "[[ 9.89132336e+00  4.90497564e-01  8.02327495e-01]\n",
            " [ 6.75946324e-25 -1.37761662e+00  3.40121641e-01]\n",
            " [ 4.40622912e-38 -1.11530120e-13 -5.13706744e-01]]\n",
            "Eigenvalue: 9.891320757684891\n",
            "Eigenvector: [0.47805354 0.86429078 1.        ]\n",
            "Eigenvalue: 0.08333339306853582\n",
            "Eigenvector: [0.99999915 1.         0.99999879]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H8wWhfsDCel",
        "outputId": "1358dffa-831c-4121-e082-faa83df4a8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE7Z5ym96Dy6"
      },
      "outputs": [],
      "source": [
        "#Important libraries to import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LAB 6 - I\n",
        "# Download the data from the given link https://www.kaggle.com/datasets/priy998/golf-play-dataset?select=golf_df.csv\n",
        "!pip install chefboost\n",
        "golf_dataset = pd.read_csv('/content/golf_df.csv') \n",
        "from chefboost import Chefboost as chef\n",
        "config = {'algorithm': 'C4.5'}\n",
        "model = chef.fit(golf_dataset, config = config, target_label = 'Play')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbSDg3KkUD06",
        "outputId": "75105bfe-c2ee-450c-c697-7c9bb0f27d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chefboost in /usr/local/lib/python3.9/dist-packages (0.0.17)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.9/dist-packages (from chefboost) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from chefboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.9/dist-packages (from chefboost) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.9/dist-packages (from chefboost) (5.9.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.22.0->chefboost) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.22.0->chefboost) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=0.22.0->chefboost) (1.16.0)\n",
            "[INFO]:  1 CPU cores will be allocated in parallel running\n",
            "C4.5  tree is going to be built...\n",
            "-------------------------\n",
            "finished in  0.9708230495452881  seconds\n",
            "-------------------------\n",
            "Evaluate  train set\n",
            "-------------------------\n",
            "Accuracy:  100.0 % on  14  instances\n",
            "Labels:  ['no' 'yes']\n",
            "Confusion matrix:  [[5, 0], [0, 9]]\n",
            "Precision:  100.0 %, Recall:  100.0 %, F1:  100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LAB_6 -- II\n",
        "wine_dataset  = datasets.load_wine()\n",
        "wine_x = wine_dataset.data\n",
        "wine_y = wine_dataset.target\n",
        "wine_x_train,wine_x_test,wine_y_train,wine_y_test = train_test_split(wine_x,wine_y,test_size = 0.3)\n",
        "\n",
        "decision_tree_clf = DecisionTreeClassifier(criterion = 'entropy') # As id3 tree algorithm use entropy for loss calculation\n",
        "decision_tree_clf.fit(wine_x_train,wine_y_train)\n",
        "\n",
        "print(f\"ID3 Accuracy for Wine Dataset : {accuracy_score(wine_y_test,decision_tree_clf.predict(wine_x_test))*100}%\")\n",
        "print(f\"ID3 Classification Report: \\n{classification_report(wine_y_test, decision_tree_clf.predict(wine_x_test))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9OtLgQjUD3h",
        "outputId": "97d87489-ea10-4026-e12f-6997fb30262f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID3 Accuracy for Wine Dataset : 92.5925925925926%\n",
            "ID3 Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91        17\n",
            "           1       0.89      0.89      0.89        18\n",
            "           2       1.00      0.95      0.97        19\n",
            "\n",
            "    accuracy                           0.93        54\n",
            "   macro avg       0.93      0.93      0.93        54\n",
            "weighted avg       0.93      0.93      0.93        54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LAB 7 \n",
        "#Download the datset from this link - - https://www.kaggle.com/datasets/devvret/congressional-voting-records?select=house-votes-84.csv\n",
        "df = pd.read_csv('/content/house-votes-84.csv')## Upload the datsets into colab and copy the path\n",
        "\n",
        "house_votes_x = df.drop(['Class Name'],axis = 1)\n",
        "house_votes_y=  df['Class Name']\n",
        "\n",
        "for col in house_votes_x.columns:\n",
        "    house_votes_x[col] = [1 if vote == 'y' else 0 for vote in house_votes_x[col]]\n",
        "house_votes_y = [1 if vote == 'republican' else 0 for vote in house_votes_y]\n",
        "house_votes_x_train,house_votes_x_test,house_votes_y_train,house_votes_y_test = train_test_split(house_votes_x,house_votes_y,test_size = 0.3)\n",
        "\n",
        "naive_bayes_classifier= GaussianNB().fit(house_votes_x_train,house_votes_y_train)\n",
        "print(f\"Naive Bayes Accuracy for Wine Dataset : {accuracy_score(house_votes_y_test,naive_bayes_classifier.predict(house_votes_x_test))*100}%\")\n",
        "print(f\"Naive Bayes Classification Report: \\n{classification_report(house_votes_y_test,naive_bayes_classifier.predict(house_votes_x_test))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8yJt7YxUD7E",
        "outputId": "d0630b5a-438b-4340-a9b6-6c692b55398b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy for Wine Dataset : 93.89312977099237%\n",
            "Naive Bayes Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94        69\n",
            "           1       0.97      0.90      0.93        62\n",
            "\n",
            "    accuracy                           0.94       131\n",
            "   macro avg       0.94      0.94      0.94       131\n",
            "weighted avg       0.94      0.94      0.94       131\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LAB -- 8\n",
        "iris = datasets.load_iris()\n",
        "iris_data_x = iris.data\n",
        "iris_data_y = iris.target\n",
        "\n",
        "iris_data_x_train,iris_data_x_test,iris_data_y_train,iris_data_y_test = train_test_split(iris_data_x,iris_data_y,test_size = 0.3)\n",
        "KNN_Clf = KNeighborsClassifier().fit(iris_data_x_train,iris_data_y_train)\n",
        "print(f\"K-Nearest Neighbors classifier Accuracy for Wine Dataset : {accuracy_score(iris_data_y_test,KNN_Clf.predict(iris_data_x_test))*100}%\")\n",
        "print(f\"K-Nearest Neighbors classifier Classification Report: \\n{classification_report(iris_data_y_test,KNN_Clf.predict(iris_data_x_test))}\")"
      ],
      "metadata": {
        "id": "NXcit8RPeZ0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc80a20f-8dcc-4045-cf2e-3d215702d6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Nearest Neighbors classifier Accuracy for Wine Dataset : 95.55555555555556%\n",
            "K-Nearest Neighbors classifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.88      1.00      0.94        15\n",
            "           2       1.00      0.86      0.92        14\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.95      0.95        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LAB -- 9\n",
        "url ='https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data' # data for lab 9\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "parkinson_data_x  = data.drop(['status','name'],axis=1)\n",
        "parkinson_data_y = data['status']\n",
        "\n",
        "parkinson_data_x_train ,parkinson_data_x_test, parkinson_data_y_train ,parkinson_data_y_test= train_test_split(parkinson_data_x,parkinson_data_y,test_size  = 0.3)\n",
        "svm_clf = SVC().fit(parkinson_data_x_train,parkinson_data_y_train)\n",
        "print(f\"Support Vector Classifier Accuracy for Wine Dataset : {accuracy_score(parkinson_data_y_test,svm_clf.predict(parkinson_data_x_test))*100}%\")\n",
        "print(f\"Support Vector Classifier Classification Report: \\n{classification_report(parkinson_data_y_test,svm_clf.predict(parkinson_data_x_test))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ulg7N3k3fDI",
        "outputId": "014f53a4-0d84-44c9-8a3b-16d8a12449b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Classifier Accuracy for Wine Dataset : 71.1864406779661%\n",
            "Support Vector Classifier Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.11      0.19        19\n",
            "           1       0.70      1.00      0.82        40\n",
            "\n",
            "    accuracy                           0.71        59\n",
            "   macro avg       0.85      0.55      0.51        59\n",
            "weighted avg       0.80      0.71      0.62        59\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LAB -- 10\n",
        "from sklearn.model_selection import train_test_split\n",
        "x= iris.data\n",
        "y = iris.target\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n",
        "\n",
        "\n",
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred_svm = clf.predict(x_test)\n",
        "clf.support_vectors_\n",
        "print(f\"SVM Classification Report: \\n{classification_report(y_test, y_pred_svm)}\")\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn  = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "knn  = knn.fit(x_train,y_train)\n",
        "y_pred_knn = knn.predict(x_test)\n",
        "print(f\"KNN Classification Report: \\n{classification_report(y_test, y_pred_knn)}\")\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "id3 = DecisionTreeClassifier(criterion='entropy')\n",
        "id3.fit(x_train, y_train)\n",
        "y_pred_id3 = id3.predict(x_test)\n",
        "accuracy_id3 = accuracy_score(y_test, y_pred_id3)\n",
        "print(f\"ID3 Accuracy: {accuracy_id3}\")\n",
        "print(f\"ID3 Classification Report: \\n{classification_report(y_test, y_pred_id3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izgKDBGo3fF_",
        "outputId": "cff609ce-acdc-4840-f303-e8f4873acfce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID3 Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       0.94      1.00      0.97        16\n",
            "           2       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "ID3 Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00        16\n",
            "           2       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "ID3 Accuracy: 0.9555555555555556\n",
            "ID3 Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       0.89      1.00      0.94        16\n",
            "           2       1.00      0.86      0.92        14\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.95      0.95        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZh-tU853fK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sSnJV9XiwvQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LAB -- 12\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Prepare the data\n",
        "california_data = fetch_california_housing()\n",
        "X = california_data.data\n",
        "y = california_data.target.reshape(-1, 1)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Initialize the network\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size = 32\n",
        "output_size = 1\n",
        "weights1 = np.random.randn(input_size, hidden_size) / np.sqrt(input_size)\n",
        "weights2 = np.random.randn(hidden_size, output_size) / np.sqrt(hidden_size)\n",
        "\n",
        "# Step 3: Forward pass\n",
        "def forward(X):\n",
        "    hidden_layer = np.dot(X, weights1)\n",
        "    hidden_layer = np.maximum(hidden_layer, 0)\n",
        "    output_layer = np.dot(hidden_layer, weights2)\n",
        "    return output_layer\n",
        "\n",
        "# Step 4: Calculate error\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean(np.square(y_true - y_pred))\n",
        "\n",
        "# Step 5: Backward pass\n",
        "def backward(X, y_true, y_pred, hidden_layer):\n",
        "    output_error = y_pred - y_true\n",
        "    output_delta = output_error / X.shape[0]\n",
        "    hidden_error = np.dot(output_delta, weights2.T)\n",
        "    hidden_delta = hidden_error * (hidden_layer > 0)\n",
        "    weights2_update = np.dot(hidden_layer.T, output_delta)\n",
        "    weights1_update = np.dot(X.T, hidden_delta)\n",
        "    return weights1_update, weights2_update\n",
        "\n",
        "# Step 6: Train the network\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    hidden_layer = np.dot(X_train, weights1)\n",
        "    hidden_layer = np.maximum(hidden_layer, 0)\n",
        "    output_layer = np.dot(hidden_layer, weights2)\n",
        "   \n",
        "    # Calculate loss\n",
        "    loss = mse_loss(y_train, output_layer)\n",
        "   \n",
        "    # Backward pass\n",
        "    weights1_update, weights2_update = backward(X_train, y_train, output_layer, hidden_layer)\n",
        "    weights1 -= learning_rate * weights1_update\n",
        "    weights2 -= learning_rate * weights2_update\n",
        "   \n",
        "    # Print progress\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "   \n",
        "# Step 7: Evaluate the network\n",
        "y_pred = forward(X_test)\n",
        "rmse = np.sqrt(mse_loss(y_test, y_pred))\n",
        "print(f\"RMSE = {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1ZRfqnt3fNv",
        "outputId": "2131b02a-b423-4b70-e7f8-00e06f6ae5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 5.9958\n",
            "Epoch 100: Loss = 1.0898\n",
            "Epoch 200: Loss = 0.9484\n",
            "Epoch 300: Loss = 0.9010\n",
            "Epoch 400: Loss = 0.8674\n",
            "Epoch 500: Loss = 0.8408\n",
            "Epoch 600: Loss = 0.8186\n",
            "Epoch 700: Loss = 0.7999\n",
            "Epoch 800: Loss = 0.7838\n",
            "Epoch 900: Loss = 0.7698\n",
            "RMSE = 0.8876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LAB -- 13\n",
        "import numpy as np\n",
        "# defining the data points\n",
        "data = np.array([[2, 10], [2, 5], [8, 4], [5, 8], [7, 5], [6, 4], [1, 2], [4, 9]])\n",
        "# defining the initial cluster centers\n",
        "centers = np.array([[2, 10], [5, 8], [1, 2]])\n",
        "# defining the number of clusters\n",
        "K = 3\n",
        "# defining the maximum number of iterations\n",
        "max_iters = 10\n",
        "# defining the Euclidean distance function\n",
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "# k-means clustering algorithm\n",
        "for i in range(max_iters):\n",
        "    # initializing empty clusters\n",
        "    clusters = [[] for _ in range(K)]\n",
        "    # assigning data points to the closest cluster center\n",
        "    for point in data:\n",
        "        distances = [euclidean_distance(point, center) for center in centers]\n",
        "        closest_center = np.argmin(distances)\n",
        "        clusters[closest_center].append(point)\n",
        "# updating the cluster centers\n",
        "for j in range(K):\n",
        "    centers[j] = np.mean(clusters[j], axis=0)\n",
        "# printing the cluster centers after the first round of execution\n",
        "if i == 0:\n",
        "    print(\"Cluster centers after the first round of execution:\")\n",
        "    print(centers[i])\n",
        "    print()\n",
        "# printing the first three clusters\n",
        "if i < 3:\n",
        "    print(\"Cluster\", i+1, \":\", clusters[i])\n",
        "\n",
        "centers,clusters\n",
        "#Each line  in a cluster is a seperate cluster"
      ],
      "metadata": {
        "id": "HZsrlvxQeZ2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9527da-164b-41c6-97d6-4dd70be65ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 2, 10],\n",
              "        [ 6,  6],\n",
              "        [ 1,  3]]),\n",
              " [[array([ 2, 10])],\n",
              "  [array([8, 4]), array([5, 8]), array([7, 5]), array([6, 4]), array([4, 9])],\n",
              "  [array([2, 5]), array([1, 2])]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOqkYn9cPFSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}